{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammed/pytorch_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Ultralytics YOLO ðŸš€, GPL-3.0 license\n",
    "import torch\n",
    "from numpy import random\n",
    "import math\n",
    "import cv2\n",
    "from deep_sort_pytorch.utils.parser import get_config\n",
    "from deep_sort_pytorch.deep_sort import DeepSort\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "\n",
    "\n",
    "# setup line coordinates\n",
    "limitsDown = [612, 1056, 1350, 1000] # down line coordinates [x1, y1, x2, y2]\n",
    "limitsUp = [1440, 928, 1850, 876] # up line coordinates [x1, y1, x2, y2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "object_counter = {} # Enter the object you want to count\n",
    "\n",
    "object_counter1 = {} # leave the object you want to count\n",
    "\n",
    "totalCountUp = [] # total count of objects that crossed the line going up\n",
    "totalCountDown = [] # total count of objects that crossed the line going down\n",
    "deepsort = None\n",
    "\n",
    "def init_tracker():\n",
    "    global deepsort\n",
    "    cfg_deep = get_config()\n",
    "    cfg_deep.merge_from_file(\"deep_sort_pytorch/configs/deep_sort.yaml\")\n",
    "\n",
    "    deepsort= DeepSort(cfg_deep.DEEPSORT.REID_CKPT,\n",
    "                            max_dist=cfg_deep.DEEPSORT.MAX_DIST, min_confidence=cfg_deep.DEEPSORT.MIN_CONFIDENCE,\n",
    "                            nms_max_overlap=cfg_deep.DEEPSORT.NMS_MAX_OVERLAP, max_iou_distance=cfg_deep.DEEPSORT.MAX_IOU_DISTANCE,\n",
    "                            max_age=cfg_deep.DEEPSORT.MAX_AGE, n_init=cfg_deep.DEEPSORT.N_INIT, nn_budget=cfg_deep.DEEPSORT.NN_BUDGET,\n",
    "                            use_cuda=True)\n",
    "##########################################################################################\n",
    "\n",
    "speed_line_queue = {}\n",
    "data_deque = {}\n",
    "\n",
    "\n",
    "# calculate the speed of the object\n",
    "def estimate_speed(location1, location2):\n",
    "    d_pixels = math.sqrt(math.pow(location2[0] - location1[0], 2) + math.pow(location2[1] - location1[1], 2))\n",
    "    ppm = 8.8\n",
    "    d_meters = d_pixels / ppm\n",
    "    fps = 12.5\n",
    "    speed = d_meters * fps * 3.6\n",
    "    return int(speed)\n",
    "\n",
    "# convert the coordinates of the bounding box to the center coordinates of the bounding box\n",
    "def xyxy_to_xywh(*xyxy):\n",
    "    \"\"\"\" Calculates the relative bounding box from absolute pixel values. \"\"\"\n",
    "    bbox_left = min([xyxy[0].item(), xyxy[2].item()])\n",
    "    bbox_top = min([xyxy[1].item(), xyxy[3].item()])\n",
    "    bbox_w = abs(xyxy[0].item() - xyxy[2].item())\n",
    "    bbox_h = abs(xyxy[1].item() - xyxy[3].item())\n",
    "    x_c = (bbox_left + bbox_w / 2)\n",
    "    y_c = (bbox_top + bbox_h / 2)\n",
    "    w = bbox_w\n",
    "    h = bbox_h\n",
    "    return x_c, y_c, w, h\n",
    "\n",
    "\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    if label == 0: #person\n",
    "        color = (85,45,255)\n",
    "    elif label == 2: # Car\n",
    "        color = (222,82,175)\n",
    "    elif label == 3:  # Motobike\n",
    "        color = (0, 204, 255)\n",
    "    elif label == 5:  # Bus\n",
    "        color = (0, 149, 255)\n",
    "    else:\n",
    "        color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "\n",
    "\n",
    "# draw the bounding box and the speed of the object\n",
    "def UI_box(x, img, color=None, label=None, id=id, line_thickness=None):\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    w, h = int(x[2] - x[0]), int(x[3] - x[1])\n",
    "    cx, cy = int(x[0] + w / 2), int(x[1] + h / 2)\n",
    "    cv2.circle(img, (cx, cy), 2, (0,0,255), cv2.FILLED)\n",
    "    #cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        \n",
    "        img = cv2.rectangle(img, (c1[0], c1[1] - t_size[1] - 3), (c1[0] + t_size[0], c1[1] - 2), color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # if the object is in the area of â€‹â€‹the line, count the object\n",
    "        if limitsUp[0] < cx < limitsUp[2] and limitsUp[1] - 50 < cy < limitsUp[3] + 50:\n",
    "            \n",
    "            if totalCountUp.count(id) == 0:\n",
    "                totalCountUp.append(id)\n",
    "                cv2.line(img,(limitsUp[0],limitsUp[1]),(limitsUp[2],limitsUp[3]),(255,255,0),5)\n",
    "\n",
    "        # if the object is in the area of â€‹â€‹the line, count the object\n",
    "        if limitsDown[0] < cx < limitsDown[2] and limitsDown[1] - 50 < cy < limitsDown[3] + 50:\n",
    "            \n",
    "            if totalCountDown.count(id) == 0:\n",
    "                totalCountDown.append(id)\n",
    "                cv2.line(img,(limitsDown[0],limitsDown[1]),(limitsDown[2],limitsDown[3]),(255,255,0),5)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# draw the bounding box and the speed of the object\n",
    "def draw_boxes(img, bbox, names,object_id, identities=None, offset=(0, 0)):\n",
    "\n",
    "    cv2.line(img,(limitsUp[0],limitsUp[1]),(limitsUp[2],limitsUp[3]),(0,255,0),5)\n",
    "    cv2.putText(img,\"up\",(limitsUp[0],limitsUp[1]-15),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.line(img,(limitsDown[0],limitsDown[1]),(limitsDown[2],limitsDown[3]),(0,0,255),5)\n",
    "    cv2.putText(img,\"Down\",(limitsDown[0],limitsDown[1]-15),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "\n",
    "    global totalCountUp\n",
    "    global totalCountDown\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    for key in list(data_deque):\n",
    "      if key not in identities:\n",
    "        data_deque.pop(key)\n",
    "\n",
    "    for i, box in enumerate(bbox):\n",
    "        x1, y1, x2, y2 = [int(i) for i in box]\n",
    "        x1 += offset[0]\n",
    "        x2 += offset[0]\n",
    "        y1 += offset[1]\n",
    "        y2 += offset[1]\n",
    "\n",
    "        # bounding box center\n",
    "        center = int(x1+((x2-x1) / 2)), int(y1+(y2 - y1) / 2)\n",
    "\n",
    "        # get ID of object\n",
    "        id = int(identities[i]) if identities is not None else 0\n",
    "\n",
    "        # create new buffer for new object\n",
    "        if id not in data_deque:  \n",
    "            data_deque[id] = deque(maxlen= 64)\n",
    "            speed_line_queue[id] = []\n",
    "\n",
    "\n",
    "        color = compute_color_for_labels(object_id[i])\n",
    "        obj_name = names[object_id[i]]\n",
    "        label = '{}{:d}'.format(\"\", id) + \":\"+ '%s' % (obj_name)\n",
    "\n",
    "        # add center to buffer\n",
    "        data_deque[id].appendleft(center)\n",
    "        # if data deque has more than two value, calculate speed\n",
    "        if len(data_deque[id]) >= 2:\n",
    "            object_speed = estimate_speed(data_deque[id][1], data_deque[id][0])\n",
    "            speed_line_queue[id].append(object_speed)\n",
    "          \n",
    "\n",
    "        try:\n",
    "            label = label + \" \" + str(sum(speed_line_queue[id])//len(speed_line_queue[id])) + \"km/h\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        UI_box(box, img, label=label, color=color, id=id ,line_thickness=2)\n",
    "        # draw trail\n",
    "        for i in range(1, len(data_deque[id])):\n",
    "            # check if on buffer value is none\n",
    "            if data_deque[id][i - 1] is None or data_deque[id][i] is None:\n",
    "                continue\n",
    "            # generate dynamic thickness of trails\n",
    "            thickness = int(np.sqrt(64 / float(i + i)) * 1.5)\n",
    "            # draw trails\n",
    "            cv2.line(img, data_deque[id][i - 1], data_deque[id][i], color, thickness)\n",
    "\n",
    "        # Display count in top right and left corner\n",
    "        \n",
    "        cv2.circle(img,(150,100),50,(0,0,255),-1)\n",
    "        cv2.circle(img,(width-150,100),50,(0,255,0),-1)\n",
    "        cv2.putText(img,str(len(totalCountDown)),(130,120),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,0),5)\n",
    "        cv2.putText(img,str(len(totalCountUp)),(width-170,120),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,0),5)\n",
    "\n",
    "        cv2.putText(img, \"Total Down count: \" , (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        cv2.putText(img, \"Total Up count: \", (width - 280, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yolov7\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import cv2\n",
    "init_tracker()\n",
    "\n",
    "# load yolov7 model\n",
    "# pip install yolov7detect\n",
    "model = yolov7.load(\"yolov7x.pt\",trace=False)#),device=\"cuda:0\")\n",
    "print(\"model loaded\")\n",
    "print(\"Names: \", model.names)\n",
    "\n",
    "colors = sv.ColorPalette.default()\n",
    "# initiate polygon zone\n",
    "polygons = [ np.array([\n",
    "    [480, 472],[600, 996],[1300, 924],[712, 448]\n",
    "]),\n",
    "np.array([\n",
    "    [820, 464],[1364, 864],[1800, 820],[1000, 448]\n",
    "])]\n",
    "\n",
    "# extract video frame\n",
    "# istanbul live stream surveillance camera url\n",
    "cap = cv2.VideoCapture(\"https://601a55c88ec6d.streamlock.net/hls/185.stream/chunklist.m3u8\")\n",
    "w,h = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"fps: \", cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "zones = [\n",
    "    sv.PolygonZone(\n",
    "        polygon=polygon, \n",
    "        frame_resolution_wh=(w,h)\n",
    "    )\n",
    "    for polygon\n",
    "    in polygons\n",
    "]\n",
    "zone_annotators = [\n",
    "    sv.PolygonZoneAnnotator(\n",
    "        zone=zone, \n",
    "        color=colors.by_idx(index), \n",
    "        thickness=4,\n",
    "        text_thickness=8,\n",
    "        text_scale=4\n",
    "    )\n",
    "    for index, zone\n",
    "    in enumerate(zones)\n",
    "]\n",
    "box_annotators = [\n",
    "    sv.BoxAnnotator(\n",
    "        color=colors.by_idx(index), \n",
    "        thickness=4, \n",
    "        text_thickness=4, \n",
    "        text_scale=2\n",
    "        )\n",
    "    for index\n",
    "    in range(len(polygons))\n",
    "]\n",
    "\n",
    "cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"test\", 1200, 650)\n",
    "\n",
    "# video write\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#out = cv2.VideoWriter('output.avi',fourcc, fps, (w,h))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # detect\n",
    "        results = model(frame, size=640)\n",
    "        detections = sv.Detections.from_yolov5(results)\n",
    "        detections = (detections[(detections.class_id == 2)] or detections[(detections.class_id == 5)] or detections[(detections.class_id == 3)] or detections[(detections.class_id == 7)])\n",
    "        # 2,3,5 = person, car, bus just detect these objects\n",
    "    \n",
    "\n",
    "        xywh_bboxs = []\n",
    "        confs = []\n",
    "        oids = []\n",
    "        outputs = []\n",
    "        for xyxy, conf, cls in zip(detections.xyxy, detections.confidence, detections.class_id):\n",
    "            x_c, y_c, bbox_w, bbox_h = xyxy_to_xywh(*xyxy)\n",
    "            xywh_obj = [x_c, y_c, bbox_w, bbox_h]\n",
    "            xywh_bboxs.append(xywh_obj)\n",
    "            confs.append([conf.item()])\n",
    "            oids.append(int(cls))\n",
    "        xywhs = torch.Tensor(xywh_bboxs)\n",
    "        confss = torch.Tensor(confs)\n",
    "        if xywhs.nelement() > 0:\n",
    "            outputs = deepsort.update(xywhs, confss, oids, frame)\n",
    "        if len(outputs) > 0:\n",
    "            bbox_xyxy = outputs[:, :4]\n",
    "            identities = outputs[:, -2]\n",
    "            object_id = outputs[:, -1]\n",
    "            \n",
    "            frame = draw_boxes(frame, bbox_xyxy, model.names, object_id,identities)\n",
    "\n",
    "\n",
    "\n",
    "        for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
    "        # annotate\n",
    "            \n",
    "            mask = zone.trigger(detections=detections)\n",
    "            \n",
    "            detections_filtered = detections[mask]\n",
    "\n",
    "            #labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "            frame = box_annotator.annotate(scene=frame, detections=detections_filtered, skip_label=False)\n",
    "            frame = zone_annotator.annotate(scene=frame)\n",
    "            #print(zone_count)\n",
    "            #cv2.circle(frame,(815,191),50,(255,255,255),-1)\n",
    "            #cv2.putText(frame,str(zone_count),(800,185),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,0),5)\n",
    "\n",
    "        # write video\n",
    "        #out.write(frame)\n",
    "        cv2.imshow(\"test\", frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a05d0ef2f709f96bc2f8332913f5fe77e968cfc62dc4d12022b9f5d5edbc7cf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
